@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
},
@InProceedings{pmlr-v37-schulman15,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1889--1897},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/schulman15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/schulman15.html},
  abstract = 	 {In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.}
},
@Inbook{Joyce2011,
author="Joyce, James M.",
editor="Lovric, Miodrag",
title="Kullback-Leibler Divergence",
bookTitle="International Encyclopedia of Statistical Science",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="720--722",
isbn="978-3-642-04898-2",
doi="10.1007/978-3-642-04898-2_327",
url="https://doi.org/10.1007/978-3-642-04898-2_327"
},
@inproceedings{Engstrom2020Implementation,
title={Implementation Matters in Deep RL: A Case Study on PPO and TRPO},
author={Logan Engstrom and Andrew Ilyas and Shibani Santurkar and Dimitris Tsipras and Firdaus Janoos and Larry Rudolph and Aleksander Madry},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=r1etN1rtPB}
}


